{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787c8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy.sparse import csr_matrix\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b1f02",
   "metadata": {},
   "source": [
    "### Write a python script to convert the data into a dataframe (check the section below for the head and tail of dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae57c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premise</td>\n",
       "      <td>Take Olympic games which is a form of competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premise</td>\n",
       "      <td>The high technology and new ideas applied into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premise</td>\n",
       "      <td>pollutions are not just caused by the burning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premise</td>\n",
       "      <td>the improvements of work efficiency also attri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>addressing pollution and traffic issues only b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>Premise</td>\n",
       "      <td>whether it can work out for alleviating traffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>Premise</td>\n",
       "      <td>price control institution has been used in ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>Claim</td>\n",
       "      <td>it seems not easy to increase petrol price ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>Premise</td>\n",
       "      <td>governments have a macro-economic perspective ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6089 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text\n",
       "0     MajorClaim  we should attach more importance to cooperatio...\n",
       "1        Premise  Take Olympic games which is a form of competit...\n",
       "2        Premise  The high technology and new ideas applied into...\n",
       "3        Premise  pollutions are not just caused by the burning ...\n",
       "4        Premise  the improvements of work efficiency also attri...\n",
       "...          ...                                                ...\n",
       "6084  MajorClaim  addressing pollution and traffic issues only b...\n",
       "6085     Premise  whether it can work out for alleviating traffi...\n",
       "6086     Premise  price control institution has been used in ple...\n",
       "6087       Claim  it seems not easy to increase petrol price ins...\n",
       "6088     Premise  governments have a macro-economic perspective ...\n",
       "\n",
       "[6089 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the folder path containing the text files\n",
    "folder_path = r\"C:\\Users\\mitra\\Desktop\\INNOMATICS(MITRABHANU PANDA)\\GEN AI (ADVANCE)\\5. ASSIGNMENTS\\ASSIGNMENT-1\\text\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read().strip()\n",
    "            # Append the filename and content to the list\n",
    "            data.append([filename, content])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Filename', 'Content'])\n",
    "\n",
    "\n",
    "# Split & create a Label Column\n",
    "df[\"label\"]=df[\"Content\"].apply(lambda x:x.split(\"\\n\")[0])\n",
    "\n",
    "# Split & create a text Column\n",
    "df[\"text\"]=df[\"Content\"].apply(lambda x:x.split(\"\\n\")[1])\n",
    "\n",
    "# Drop the unwanted Column\n",
    "df.drop([\"Content\",\"Filename\"],axis=1,inplace=True)\n",
    "\n",
    "# Show the Dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1089f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premise</td>\n",
       "      <td>Take Olympic games which is a form of competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premise</td>\n",
       "      <td>The high technology and new ideas applied into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premise</td>\n",
       "      <td>pollutions are not just caused by the burning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premise</td>\n",
       "      <td>the improvements of work efficiency also attri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0  MajorClaim  we should attach more importance to cooperatio...\n",
       "1     Premise  Take Olympic games which is a form of competit...\n",
       "2     Premise  The high technology and new ideas applied into...\n",
       "3     Premise  pollutions are not just caused by the burning ...\n",
       "4     Premise  the improvements of work efficiency also attri..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85f77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>addressing pollution and traffic issues only b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>Premise</td>\n",
       "      <td>whether it can work out for alleviating traffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>Premise</td>\n",
       "      <td>price control institution has been used in ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>Claim</td>\n",
       "      <td>it seems not easy to increase petrol price ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>Premise</td>\n",
       "      <td>governments have a macro-economic perspective ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text\n",
       "6084  MajorClaim  addressing pollution and traffic issues only b...\n",
       "6085     Premise  whether it can work out for alleviating traffi...\n",
       "6086     Premise  price control institution has been used in ple...\n",
       "6087       Claim  it seems not easy to increase petrol price ins...\n",
       "6088     Premise  governments have a macro-economic perspective ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee584e92",
   "metadata": {},
   "source": [
    "### In what format are the observations available in the given raw data?\n",
    "   * Ans :--> text files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140e5ce",
   "metadata": {},
   "source": [
    "### In what format are the observations available in the given raw data?\n",
    "\n",
    "   * Ans :--> 6089"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725415f",
   "metadata": {},
   "source": [
    "### How many files are having 'Premise' label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9449fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()[\"Premise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1653e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013343bd",
   "metadata": {},
   "source": [
    "### What is the maximum number of character level tokens in a document in raw 'text' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6712bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of character-level tokens in a document is: 344\n"
     ]
    }
   ],
   "source": [
    "# Function to tokenize text at the character level\n",
    "def char_tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "# Apply the tokenizer to each document and calculate the length of the token list\n",
    "df['char_token_count'] = df['text'].apply(lambda x: len(char_tokenize(x)))\n",
    "\n",
    "# Find the maximum number of character-level tokens in the 'text' column\n",
    "max_char_tokens = df['char_token_count'].max()\n",
    "\n",
    "print(f\"The maximum number of character-level tokens in a document is: {max_char_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd462a",
   "metadata": {},
   "source": [
    "### What is the maximum number of word level tokens in a document in raw 'text' columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5082262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Number of Word Level Tokens:  67\n"
     ]
    }
   ],
   "source": [
    "df[\"word_token_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "max_words_token = df['word_token_count'].max()\n",
    "print(\"Max Number of Word Level Tokens: \",max_words_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cac4784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>char_token_count</th>\n",
       "      <th>word_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premise</td>\n",
       "      <td>Take Olympic games which is a form of competit...</td>\n",
       "      <td>297</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premise</td>\n",
       "      <td>The high technology and new ideas applied into...</td>\n",
       "      <td>154</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premise</td>\n",
       "      <td>pollutions are not just caused by the burning ...</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premise</td>\n",
       "      <td>the improvements of work efficiency also attri...</td>\n",
       "      <td>127</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>addressing pollution and traffic issues only b...</td>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>Premise</td>\n",
       "      <td>whether it can work out for alleviating traffi...</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>Premise</td>\n",
       "      <td>price control institution has been used in ple...</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>Claim</td>\n",
       "      <td>it seems not easy to increase petrol price ins...</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>Premise</td>\n",
       "      <td>governments have a macro-economic perspective ...</td>\n",
       "      <td>107</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6089 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text  \\\n",
       "0     MajorClaim  we should attach more importance to cooperatio...   \n",
       "1        Premise  Take Olympic games which is a form of competit...   \n",
       "2        Premise  The high technology and new ideas applied into...   \n",
       "3        Premise  pollutions are not just caused by the burning ...   \n",
       "4        Premise  the improvements of work efficiency also attri...   \n",
       "...          ...                                                ...   \n",
       "6084  MajorClaim  addressing pollution and traffic issues only b...   \n",
       "6085     Premise  whether it can work out for alleviating traffi...   \n",
       "6086     Premise  price control institution has been used in ple...   \n",
       "6087       Claim  it seems not easy to increase petrol price ins...   \n",
       "6088     Premise  governments have a macro-economic perspective ...   \n",
       "\n",
       "      char_token_count  word_token_count  \n",
       "0                   72                10  \n",
       "1                  297                58  \n",
       "2                  154                26  \n",
       "3                  137                20  \n",
       "4                  127                19  \n",
       "...                ...               ...  \n",
       "6084                84                13  \n",
       "6085                92                15  \n",
       "6086               131                23  \n",
       "6087                52                 9  \n",
       "6088               107                15  \n",
       "\n",
       "[6089 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b7d31",
   "metadata": {},
   "source": [
    "### Applying Text Cleaning\n",
    "\n",
    "#### Cleaning Steps:\n",
    " - A valid token should only contain alphanumeric and \".\"\n",
    " - Convert to lower\n",
    " - word tokenize\n",
    " - stop word removal\n",
    " - lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74920f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc): \n",
    "    # doc is a string of text\n",
    "    \n",
    "    # Let's define a regex to match special characters and digits\n",
    "    regex = \"[^a-zA-Z.]\"\n",
    "    doc = re.sub(regex, \" \", doc)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    doc = doc.lower()\n",
    "        \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf1a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>char_token_count</th>\n",
       "      <th>word_token_count</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>attach importance cooperation primary education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premise</td>\n",
       "      <td>Take Olympic games which is a form of competit...</td>\n",
       "      <td>297</td>\n",
       "      <td>58</td>\n",
       "      <td>take olympic game form competition instance ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premise</td>\n",
       "      <td>The high technology and new ideas applied into...</td>\n",
       "      <td>154</td>\n",
       "      <td>26</td>\n",
       "      <td>high technology new idea applied practice may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premise</td>\n",
       "      <td>pollutions are not just caused by the burning ...</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>pollution caused burning oil chemical pollutan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premise</td>\n",
       "      <td>the improvements of work efficiency also attri...</td>\n",
       "      <td>127</td>\n",
       "      <td>19</td>\n",
       "      <td>improvement work efficiency also attribute spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text  \\\n",
       "0  MajorClaim  we should attach more importance to cooperatio...   \n",
       "1     Premise  Take Olympic games which is a form of competit...   \n",
       "2     Premise  The high technology and new ideas applied into...   \n",
       "3     Premise  pollutions are not just caused by the burning ...   \n",
       "4     Premise  the improvements of work efficiency also attri...   \n",
       "\n",
       "   char_token_count  word_token_count  \\\n",
       "0                72                10   \n",
       "1               297                58   \n",
       "2               154                26   \n",
       "3               137                20   \n",
       "4               127                19   \n",
       "\n",
       "                                          clean_text  \n",
       "0    attach importance cooperation primary education  \n",
       "1  take olympic game form competition instance ha...  \n",
       "2  high technology new idea applied practice may ...  \n",
       "3  pollution caused burning oil chemical pollutan...  \n",
       "4  improvement work efficiency also attribute spe...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(lambda x : clean(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd1ca2",
   "metadata": {},
   "source": [
    "### After applying text cleaning, what is the maximum number of word level tokens in 'clean_text' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e4f1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of word-level tokens in a document is: 31\n"
     ]
    }
   ],
   "source": [
    "df['word_token_count_clean'] = df['clean_text'].apply(lambda x: len(word_tokenize(x)))\n",
    "\n",
    "max_word_tokens_clean = df['word_token_count_clean'].max()\n",
    "\n",
    "print(f\"The maximum number of word-level tokens in a document is: {max_word_tokens_clean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526d3d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attach importance cooperation primary education'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b421054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].apply(lambda x: len(word_tokenize(x)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1671e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(doc): \n",
    "    # doc is a string of text\n",
    "    \n",
    "    # Let's define a regex to match special characters and digits\n",
    "    regex = \"[^a-zA-Z.]\"\n",
    "    doc = re.sub(regex, \" \", doc)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    doc = doc.lower()\n",
    "        \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    clean_tokens_stem = [stemmer.stem(tokens) for tokens in filtered_tokens]\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(clean_tokens_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2267800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>char_token_count</th>\n",
       "      <th>word_token_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_token_count_clean</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MajorClaim</td>\n",
       "      <td>we should attach more importance to cooperatio...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>attach importance cooperation primary education</td>\n",
       "      <td>5</td>\n",
       "      <td>attach import cooper primari educ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Premise</td>\n",
       "      <td>Take Olympic games which is a form of competit...</td>\n",
       "      <td>297</td>\n",
       "      <td>58</td>\n",
       "      <td>take olympic game form competition instance ha...</td>\n",
       "      <td>25</td>\n",
       "      <td>take olymp game form competit instanc hard ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premise</td>\n",
       "      <td>The high technology and new ideas applied into...</td>\n",
       "      <td>154</td>\n",
       "      <td>26</td>\n",
       "      <td>high technology new idea applied practice may ...</td>\n",
       "      <td>15</td>\n",
       "      <td>high technolog new idea appli practic may lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Premise</td>\n",
       "      <td>pollutions are not just caused by the burning ...</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>pollution caused burning oil chemical pollutan...</td>\n",
       "      <td>13</td>\n",
       "      <td>pollut caus burn oil chemic pollut extra light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premise</td>\n",
       "      <td>the improvements of work efficiency also attri...</td>\n",
       "      <td>127</td>\n",
       "      <td>19</td>\n",
       "      <td>improvement work efficiency also attribute spe...</td>\n",
       "      <td>13</td>\n",
       "      <td>improv work effici also attribut speed work pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text  \\\n",
       "0  MajorClaim  we should attach more importance to cooperatio...   \n",
       "1     Premise  Take Olympic games which is a form of competit...   \n",
       "2     Premise  The high technology and new ideas applied into...   \n",
       "3     Premise  pollutions are not just caused by the burning ...   \n",
       "4     Premise  the improvements of work efficiency also attri...   \n",
       "\n",
       "   char_token_count  word_token_count  \\\n",
       "0                72                10   \n",
       "1               297                58   \n",
       "2               154                26   \n",
       "3               137                20   \n",
       "4               127                19   \n",
       "\n",
       "                                          clean_text  word_token_count_clean  \\\n",
       "0    attach importance cooperation primary education                       5   \n",
       "1  take olympic game form competition instance ha...                      25   \n",
       "2  high technology new idea applied practice may ...                      15   \n",
       "3  pollution caused burning oil chemical pollutan...                      13   \n",
       "4  improvement work efficiency also attribute spe...                      13   \n",
       "\n",
       "                                         clean_text2  \n",
       "0                  attach import cooper primari educ  \n",
       "1  take olymp game form competit instanc hard ima...  \n",
       "2  high technolog new idea appli practic may lead...  \n",
       "3  pollut caus burn oil chemic pollut extra light...  \n",
       "4  improv work effici also attribut speed work pa...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text2'] = df['text'].apply(lambda x : clean1(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75712709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attach import cooper primari educ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503a948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text2'].apply(lambda x: len(word_tokenize(x)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a878f5a",
   "metadata": {},
   "source": [
    "### Apply Vectorization using Bag of Word Technique(with default parameters) on the raw text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33cfd734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text_dtm (# of docs, # of unique vocabulary): (6089, 5973)\n",
      "Vocab: ['aaa' 'abandon' 'abbreviated' ... 'zone' 'zoo' 'zookeepers']\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectoriezer\n",
    "bow_vect = CountVectorizer()\n",
    "\n",
    "# use it to extract features from training data\n",
    "text_dtm = bow_vect.fit_transform(df['clean_text'])\n",
    "\n",
    "\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtm.shape}\")\n",
    "print(f\"Vocab: {bow_vect.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42a125ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text_dtm (# of docs, # of unique vocabulary): (6089, 5973)\n",
      "Vocab: ['aaa' 'abandon' 'abbreviated' ... 'zone' 'zoo' 'zookeepers']\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectoriezer\n",
    "bow_vect = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# use it to extract features from training data\n",
    "text_dtm = bow_vect.fit_transform(df['clean_text'])\n",
    "\n",
    "\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtm.shape}\")\n",
    "print(f\"Vocab: {bow_vect.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b16fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size occupied by X_train_transformed in Memory: 48 Bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(f\"Size occupied by X_train_transformed in Memory: {getsizeof(text_dtm)} Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d9aff",
   "metadata": {},
   "source": [
    "### Apply Vectorization using Bag of Word Vectorization(with following parameters) on the raw text column. \n",
    "1. token_pattern=None\n",
    "2. tokenizer=callable \n",
    " - use nltk word tokenizer\n",
    "3. ngram_range=(1, **n)\n",
    "4. lowercase=false\n",
    "5. preprocessor=callable \n",
    " - A valid token should only contain alphanumeric and \".\"\n",
    " - Convert to lower\n",
    " - word tokenize\n",
    " - stop word removal\n",
    " - lemmatization\n",
    "6. stop_words=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a06d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "    return nltk.word_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bda5fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of text_dtm (# of docs, # of unique vocabulary): (6089, 5982)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectoriezer\n",
    "bow_vect = CountVectorizer(token_pattern=None,\n",
    "                           tokenizer=tokenizer, \n",
    "                           ngram_range=(1, 1), \n",
    "                           lowercase=False, \n",
    "                           preprocessor=clean, \n",
    "                           stop_words=None)\n",
    "\n",
    "# use it to extract features from training data\n",
    "text_dtms = bow_vect.fit_transform(df['text'])\n",
    "\n",
    "print()\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2cd07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of text_dtm (# of docs, # of unique vocabulary): (6089, 42023)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectoriezer\n",
    "bow_vect = CountVectorizer(token_pattern=None,\n",
    "                           tokenizer=tokenizer, \n",
    "                           ngram_range=(1, 2), \n",
    "                           lowercase=False, \n",
    "                           preprocessor=clean, \n",
    "                           stop_words=None)\n",
    "\n",
    "# use it to extract features from training data\n",
    "text_dtms = bow_vect.fit_transform(df['text'])\n",
    "\n",
    "print()\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d09f5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of text_dtm (# of docs, # of unique vocabulary): (6089, 79862)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectoriezer\n",
    "bow_vect = CountVectorizer(token_pattern=None,\n",
    "                           tokenizer=tokenizer, \n",
    "                           ngram_range=(1, 3), \n",
    "                           lowercase=False, \n",
    "                           preprocessor=clean, \n",
    "                           stop_words=None)\n",
    "\n",
    "# use it to extract features from training data\n",
    "text_dtms = bow_vect.fit_transform(df['text'])\n",
    "\n",
    "print()\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtms.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
